{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-59-9343757485d1>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-9343757485d1>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV¶\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# see also 06-Natural-Language_processing notebooks. This one focuses only on doc2vec.\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import smart_open\n",
    "import collections\n",
    "import scipy.stats as stats\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV¶\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/patrickrs/Documents/GitLab/patrick-steiner/Exercises')\n",
    "target = pd.read_csv('data/train_target.csv', index_col = 0)\n",
    "features = pd.read_csv('data/train_features.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/patrickrs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#TO DO: Clean the columns (removing missing values)\n",
    "nltk.download('stopwords')\n",
    "STOP_WORDS = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def clean_sentence(val):\n",
    "    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n",
    "    regex = re.compile('([^\\s\\w]|_)+')\n",
    "    sentence = regex.sub('', val).lower()\n",
    "    sentence = re.sub(\"xxxx\", \"\", sentence)\n",
    "    sentence = re.sub(\"xxx\", \"\", sentence)\n",
    "    sentence = re.sub(\"xx\", \"\", sentence)\n",
    "    sentence = re.sub(\"\\s\\s+\", \" \", sentence)\n",
    "       \n",
    "    # stemming of words (seems not to affect accuracy, but should make things faster\n",
    "    porter = PorterStemmer()\n",
    "    words = word_tokenize(sentence)\n",
    "    sentence = \" \".join([porter.stem(word) for word in words])\n",
    "      \n",
    "    sentence = sentence.split(\" \")\n",
    "    for word in list(sentence):\n",
    "        if word in STOP_WORDS:\n",
    "            sentence.remove(word)  \n",
    "    sentence = \" \".join(sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['Consumer complaint narrative'] = [clean_sentence(narrative) for narrative in features['Consumer complaint narrative']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features['Consumer complaint narrative'], target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['world', 'financ', 'corp', 'inaccur', 'report', 'credit', 'thi', 'account', 'reflect', 'open', 'imposs', 'becaus', 'account', 'charg', 'well', 'date', 'last', 'activ', 'report', 'differ', 'transunion', 'date', 'last', 'activ', 'imper', 'credit', 'report', 'becaus', 'directli', 'affect', 'long', 'advers', 'account', 'report', 'credit', 'disput', 'thi', 'account', 'came', 'back', 'report', 'accur', 'thi', 'creditor', 'violat', 'feder', 'state', 'law', 'follow', 'complaint', 'texa', 'consum', 'credit', 'commission', 'texa', 'attorney', 'gener'], tags=Product    Consumer Loan\n",
       "Name: 19699, dtype: object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus = []\n",
    "for i in range(len(X_train)):\n",
    "    train_corpus.append(TaggedDocument(words = word_tokenize(X_train.iloc[i]), tags = y_train.iloc[i]))\n",
    "train_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wa',\n",
       "  'lienfreez',\n",
       "  'put',\n",
       "  'check',\n",
       "  'account',\n",
       "  'district',\n",
       "  'attorney',\n",
       "  'offic',\n",
       "  'call',\n",
       "  'chase',\n",
       "  'legal',\n",
       "  'depart',\n",
       "  '1014',\n",
       "  'day',\n",
       "  'lien',\n",
       "  'releas',\n",
       "  'thi',\n",
       "  'past',\n",
       "  'monday',\n",
       "  'call',\n",
       "  'chase',\n",
       "  'legal',\n",
       "  'dept',\n",
       "  'wa',\n",
       "  'told',\n",
       "  'issu',\n",
       "  'would',\n",
       "  'expedit',\n",
       "  'lien',\n",
       "  'would',\n",
       "  'releas',\n",
       "  'within',\n",
       "  '2448',\n",
       "  'hour',\n",
       "  'today',\n",
       "  'friday',\n",
       "  'lien',\n",
       "  'still',\n",
       "  'account',\n",
       "  'spoke',\n",
       "  'da',\n",
       "  'offic',\n",
       "  'spoke',\n",
       "  'chase',\n",
       "  'legal',\n",
       "  'dept',\n",
       "  '2',\n",
       "  'hour',\n",
       "  'told',\n",
       "  'work',\n",
       "  'fund',\n",
       "  'held',\n",
       "  'illeg',\n",
       "  'thi',\n",
       "  'point'],\n",
       " ['borrow',\n",
       "  'much',\n",
       "  'time',\n",
       "  'parent',\n",
       "  'could',\n",
       "  'nt',\n",
       "  'help',\n",
       "  'pay',\n",
       "  'colleg',\n",
       "  'struggl',\n",
       "  'loan',\n",
       "  'went',\n",
       "  'loan',\n",
       "  'navient',\n",
       "  'ask',\n",
       "  'mani',\n",
       "  'time',\n",
       "  'wa',\n",
       "  'abl',\n",
       "  'give',\n",
       "  'sort',\n",
       "  'lump',\n",
       "  'sum',\n",
       "  'payoff',\n",
       "  'lower',\n",
       "  'amount',\n",
       "  'owe',\n",
       "  'wa',\n",
       "  'told',\n",
       "  'could',\n",
       "  'onli',\n",
       "  'repay',\n",
       "  'found',\n",
       "  'drown',\n",
       "  'debt',\n",
       "  'unmanag',\n",
       "  'monthli',\n",
       "  'payment',\n",
       "  'got',\n",
       "  'refer',\n",
       "  'fedloan',\n",
       "  'servc',\n",
       "  'myfedloanorg',\n",
       "  'seal',\n",
       "  'us',\n",
       "  'depart',\n",
       "  'educ',\n",
       "  'paperwork',\n",
       "  'email',\n",
       "  'websit',\n",
       "  'assum',\n",
       "  'govern',\n",
       "  'entiti',\n",
       "  'seem',\n",
       "  'privat',\n",
       "  'servic',\n",
       "  'make',\n",
       "  'seem',\n",
       "  'like',\n",
       "  'part',\n",
       "  'govern',\n",
       "  'talk',\n",
       "  'inclin',\n",
       "  'trust',\n",
       "  'dure',\n",
       "  'origin',\n",
       "  'account',\n",
       "  'told',\n",
       "  'consolid',\n",
       "  'would',\n",
       "  'best',\n",
       "  'fit',\n",
       "  'best',\n",
       "  'incom',\n",
       "  'base',\n",
       "  'repay',\n",
       "  'plan',\n",
       "  'max',\n",
       "  '20',\n",
       "  'year',\n",
       "  'repay',\n",
       "  'would',\n",
       "  'get',\n",
       "  'forgiv',\n",
       "  'took',\n",
       "  'advic',\n",
       "  'guidanc',\n",
       "  'sinc',\n",
       "  'wa',\n",
       "  'pay',\n",
       "  'profession',\n",
       "  'advic',\n",
       "  'today',\n",
       "  'articl',\n",
       "  'came',\n",
       "  'use',\n",
       "  'publicli',\n",
       "  'publish',\n",
       "  'handbook',\n",
       "  'help',\n",
       "  'student',\n",
       "  'settl',\n",
       "  'feder',\n",
       "  'owe',\n",
       "  'student',\n",
       "  'debt',\n",
       "  'mine',\n",
       "  'contact',\n",
       "  'attorney',\n",
       "  'ask',\n",
       "  'basic',\n",
       "  'advic',\n",
       "  'right',\n",
       "  'might',\n",
       "  'come',\n",
       "  'settl',\n",
       "  'feder',\n",
       "  'student',\n",
       "  'loan',\n",
       "  'debt',\n",
       "  'explain',\n",
       "  'time',\n",
       "  'navient',\n",
       "  'fedloan',\n",
       "  'servc',\n",
       "  'thing',\n",
       "  'like',\n",
       "  'waiv',\n",
       "  'collect',\n",
       "  'charg',\n",
       "  'waiv',\n",
       "  'interest',\n",
       "  'settl',\n",
       "  '90',\n",
       "  'princip',\n",
       "  'mani',\n",
       "  'variat',\n",
       "  'peopl',\n",
       "  'actual',\n",
       "  'settl',\n",
       "  'feder',\n",
       "  'student',\n",
       "  'loan',\n",
       "  'debt',\n",
       "  'call',\n",
       "  'back',\n",
       "  'fedloan',\n",
       "  'servic',\n",
       "  'explain',\n",
       "  'lump',\n",
       "  'sum',\n",
       "  'money',\n",
       "  'today',\n",
       "  'want',\n",
       "  'payoff',\n",
       "  'get',\n",
       "  'forgiv',\n",
       "  'balanc',\n",
       "  'rep',\n",
       "  'told',\n",
       "  'would',\n",
       "  'take',\n",
       "  'dime',\n",
       "  'whi',\n",
       "  'peopl',\n",
       "  'settl',\n",
       "  'feder',\n",
       "  'student',\n",
       "  'loan',\n",
       "  'debt',\n",
       "  'realli',\n",
       "  'need',\n",
       "  'spend',\n",
       "  'attorney',\n",
       "  'sue',\n",
       "  'someon',\n",
       "  'settl',\n",
       "  'year',\n",
       "  'old',\n",
       "  'debt',\n",
       "  'need',\n",
       "  'good',\n",
       "  'faith',\n",
       "  'negotait',\n",
       "  'wa',\n",
       "  'given',\n",
       "  'poor',\n",
       "  'advic',\n",
       "  'becaus',\n",
       "  'tri',\n",
       "  'make',\n",
       "  'money',\n",
       "  'success',\n",
       "  'turn',\n",
       "  'debt',\n",
       "  'debt',\n",
       "  'interest',\n",
       "  'fee',\n",
       "  'thi',\n",
       "  'unfair',\n",
       "  'wa',\n",
       "  'alreadi',\n",
       "  'buri',\n",
       "  'student',\n",
       "  'loan',\n",
       "  'debt',\n",
       "  'consolid',\n",
       "  'peopll',\n",
       "  'pose',\n",
       "  'govern',\n",
       "  'agenc',\n",
       "  'go',\n",
       "  'make',\n",
       "  'never',\n",
       "  'ever',\n",
       "  'pay',\n",
       "  'thi',\n",
       "  'success',\n",
       "  'also',\n",
       "  'give',\n",
       "  '60000',\n",
       "  'join',\n",
       "  'servic',\n",
       "  'paid',\n",
       "  'gave',\n",
       "  'incom',\n",
       "  'base',\n",
       "  'repay',\n",
       "  'plan',\n",
       "  'start',\n",
       "  'pay',\n",
       "  'snuck',\n",
       "  'enrol',\n",
       "  'paperwork',\n",
       "  'payment',\n",
       "  'go',\n",
       "  'month',\n",
       "  'month',\n",
       "  'peopl',\n",
       "  'make',\n",
       "  'money',\n",
       "  'wa',\n",
       "  'alreadi',\n",
       "  'drown',\n",
       "  'truli',\n",
       "  'feel',\n",
       "  'ive',\n",
       "  'trick',\n",
       "  'enrol',\n",
       "  'thi',\n",
       "  'servic',\n",
       "  'told',\n",
       "  '20',\n",
       "  'year',\n",
       "  'would',\n",
       "  'nt',\n",
       "  'pay',\n",
       "  'anymor',\n",
       "  'qualifi',\n",
       "  'obama',\n",
       "  'repay',\n",
       "  'plan',\n",
       "  'thing',\n",
       "  'see',\n",
       "  'true',\n",
       "  'lie',\n",
       "  'im',\n",
       "  'trap',\n",
       "  'help',\n",
       "  'agre',\n",
       "  'phone',\n",
       "  'incom',\n",
       "  'base',\n",
       "  'repay',\n",
       "  'plan',\n",
       "  '20',\n",
       "  'year',\n",
       "  'sent',\n",
       "  'doc',\n",
       "  'approv',\n",
       "  'plan',\n",
       "  'wa',\n",
       "  'realli',\n",
       "  'full',\n",
       "  'balanc',\n",
       "  'ton',\n",
       "  'interest',\n",
       "  'nt',\n",
       "  'want',\n",
       "  'stop',\n",
       "  'make',\n",
       "  'monthli',\n",
       "  'payment',\n",
       "  'fear',\n",
       "  'report',\n",
       "  'delinqu',\n",
       "  'credit',\n",
       "  'continu',\n",
       "  'pay',\n",
       "  'protect']]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus = []    \n",
    "for i in range(len(X_test)):\n",
    "    test_corpus.append(word_tokenize(X_test.iloc[i]))\n",
    "test_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "  d2v_model = Doc2Vec(vector_size = 50, \n",
    "                    window = 2, \n",
    "                    min_count = 2,\n",
    "                    workers = -1,\n",
    "                    epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.build_vocab(train_corpus)\n",
    "d2v_model.train(train_corpus, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_vector = d2v_model.infer_vector(train_corpus[0].words)\n",
    "type(d2v_model.docvecs.most_similar([inferred_vector], topn=1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = d2v_model.infer_vector(train_corpus[doc_id].words)\n",
    "    pred.append(d2v_model.docvecs.most_similar([inferred_vector], topn=1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                              precision    recall  f1-score   support\n",
      "\n",
      "                                                     Bank account or service       0.08      0.09      0.09      1978\n",
      "                                                 Checking or savings account       0.08      0.07      0.07      1977\n",
      "                                                               Consumer Loan       0.08      0.09      0.08      1983\n",
      "                                                                 Credit card       0.08      0.09      0.09      1988\n",
      "                                                 Credit card or prepaid card       0.08      0.06      0.07      1983\n",
      "                                                            Credit reporting       0.08      0.09      0.09      1979\n",
      "Credit reporting, credit repair services, or other personal consumer reports       0.08      0.07      0.08      1977\n",
      "                                                             Debt collection       0.09      0.08      0.08      1980\n",
      "                          Money transfer, virtual currency, or money service       0.09      0.09      0.09      1977\n",
      "                                                                    Mortgage       0.10      0.09      0.09      1981\n",
      "                                                                Student loan       0.09      0.09      0.09      1976\n",
      "                                                       Vehicle loan or lease       0.08      0.09      0.08      1981\n",
      "\n",
      "                                                                    accuracy                           0.08     23760\n",
      "                                                                   macro avg       0.08      0.08      0.08     23760\n",
      "                                                                weighted avg       0.08      0.08      0.08     23760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model\n",
    "pred = []\n",
    "for doc_id in range(len(test_corpus)):\n",
    "    inferred_vector = d2v_model.infer_vector(test_corpus[doc_id])\n",
    "    pred.append(d2v_model.docvecs.most_similar([inferred_vector], topn=1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                              precision    recall  f1-score   support\n",
      "\n",
      "                                                     Bank account or service       0.00      0.00      0.00        22\n",
      "                                                 Checking or savings account       0.17      0.13      0.15        23\n",
      "                                                               Consumer Loan       0.11      0.12      0.11        17\n",
      "                                                                 Credit card       0.00      0.00      0.00        12\n",
      "                                                 Credit card or prepaid card       0.16      0.24      0.19        17\n",
      "                                                            Credit reporting       0.18      0.14      0.16        21\n",
      "Credit reporting, credit repair services, or other personal consumer reports       0.11      0.09      0.10        23\n",
      "                                                             Debt collection       0.11      0.10      0.11        20\n",
      "                          Money transfer, virtual currency, or money service       0.24      0.26      0.25        23\n",
      "                                                                    Mortgage       0.11      0.11      0.11        19\n",
      "                                                                Student loan       0.07      0.04      0.05        24\n",
      "                                                       Vehicle loan or lease       0.08      0.11      0.09        19\n",
      "\n",
      "                                                                    accuracy                           0.11       240\n",
      "                                                                   macro avg       0.11      0.11      0.11       240\n",
      "                                                                weighted avg       0.12      0.11      0.11       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(y_test['Product'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('data/test_features.csv', index_col = 0)\n",
    "X_test2 = test_features['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "('vect', CountVectorizer()),\n",
    "('tfidf', TfidfTransformer()),\n",
    "('clf', svm.SVC())\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = text_clf.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pd.DataFrame(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test['Id'] = y_pred_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test['Product'] = y_pred_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = y_pred_test.drop(columns = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test.to_csv(\"data/consumer_pred2\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Bank Marketing Data\n",
    "Use the bank direct marketing dataset to train a logistic regression (scikit-learn) predicting if a client will subscribe (1 or 0) to a term deposit (variable called ‘y’).\n",
    "\n",
    "Create a ML pipeline taking in account the following points:\n",
    "- Use class_weight = ‘balanced’, as the dataset is unbalanced\n",
    "\n",
    "- Use a train and test setup\n",
    "\n",
    "- Use k-fold cross-validation to choose between L1- and L2-penalty or no penalty (you will have to specify ‘penalty’ and ‘C’, logistic regression documentation)\n",
    "\n",
    "- Test the effect of penalty for a sample of only 1000 data points.\n",
    "\n",
    "- Evaluate the effect of adding more data points. What happens and why?\n",
    "\n",
    "- Once you have chosen the best model (best test score), plot the ROC curve as well as precision and recall with varying thresholds (use the precision_recall_curve function from sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", \n",
    "        color_codes=True, \n",
    "        font_scale = 2)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score \n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/patrickrs/Documents/GitLab/patrick-steiner/03-Machine-Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking = pd.read_csv(\"banking.csv\")\n",
    "hold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping basic education together\n",
    "banking['education'] = np.where(banking['education'] == 'basic.9y', 'Basic', banking['education'])\n",
    "banking['education'] = np.where(banking['education'] == 'basic.6y', 'Basic', banking['education'])\n",
    "banking['education'] = np.where(banking['education'] == 'basic.4y', 'Basic', banking['education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>Basic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.021</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.729</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>Basic</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education  default housing loan  \\\n",
       "0   44  blue-collar  married              Basic  unknown     yes   no   \n",
       "1   53   technician  married            unknown       no      no   no   \n",
       "2   28   management   single  university.degree       no     yes   no   \n",
       "3   39     services  married        high.school       no      no   no   \n",
       "4   55      retired  married              Basic       no     yes   no   \n",
       "\n",
       "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
       "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
       "2  cellular   jun         thu  ...         3      6         2      success   \n",
       "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
       "4  cellular   aug         fri  ...         1      3         1      success   \n",
       "\n",
       "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
       "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
       "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
       "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
       "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummmies for categorical vars\n",
    "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "for var in cat_vars:\n",
    "    banking[var] = banking[var].astype('category') # similar to R's factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management',\n",
       "       'retired', 'self-employed', 'services', 'student', 'technician',\n",
       "       'unemployed', 'unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if this neat trick worked:\n",
    "banking['job'].cat.codes\n",
    "banking['job'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excellent! (I later found out that this does not work. Imagine the disappointment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = banking['y']\n",
    "X = banking.drop('y', \n",
    "                 axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36548\n",
       "1     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at our dist:\n",
    "y.value_counts()\n",
    "#sns.countplot(x = y,\n",
    "#             palette = 'dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  int64\n",
       "job               category\n",
       "marital           category\n",
       "education         category\n",
       "default           category\n",
       "housing           category\n",
       "loan              category\n",
       "contact           category\n",
       "month             category\n",
       "day_of_week       category\n",
       "duration             int64\n",
       "campaign             int64\n",
       "pdays                int64\n",
       "previous             int64\n",
       "poutcome          category\n",
       "emp_var_rate       float64\n",
       "cons_price_idx     float64\n",
       "cons_conf_idx      float64\n",
       "euribor3m          float64\n",
       "nr_employed        float64\n",
       "y                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy 'constant' simply means filling with the fill_value\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                         ]\n",
    "                                  )\n",
    "# filling missing values with median and scaling\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                      ('scaler', StandardScaler())\n",
    "                                     ]\n",
    "                              )         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we use the ColumnTransformer to apply the transformations to the correct columns in the dataframe\n",
    "num_vars = X.select_dtypes(include=['int64', 'float64']).columns # numeric vars\n",
    "cat_vars = cat_vars # from previous attempt\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, num_vars),\n",
    "                                               ('cat', categorical_transformer, cat_vars)\n",
    "                                              ]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8679291090070406"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=hold, random_state=1)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000,\n",
    "                           class_weight = 'balanced' # balances weight of zeros and ones in y\n",
    "                          )\n",
    "logit = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', model)\n",
    "                       ]\n",
    "                )\n",
    "\n",
    "logit.fit(X_train,y_train)\n",
    "predictions = logit.predict(X_test)\n",
    "model_score = logit.score(X_test, y_test)\n",
    "model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#### Use k-fold cross-validation to choose between L1- and L2-penalty or no penalty (you will have to specify ‘penalty’ and ‘C’, logistic regression documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(start = .1, stop = 5, num = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.25892541e+00, 1.58489319e+00, 1.99526231e+00, 2.51188643e+00,\n",
       "       3.16227766e+00, 3.98107171e+00, 5.01187234e+00, 6.30957344e+00,\n",
       "       7.94328235e+00, 1.00000000e+01, 1.25892541e+01, 1.58489319e+01,\n",
       "       1.99526231e+01, 2.51188643e+01, 3.16227766e+01, 3.98107171e+01,\n",
       "       5.01187234e+01, 6.30957344e+01, 7.94328235e+01, 1.00000000e+02,\n",
       "       1.25892541e+02, 1.58489319e+02, 1.99526231e+02, 2.51188643e+02,\n",
       "       3.16227766e+02, 3.98107171e+02, 5.01187234e+02, 6.30957344e+02,\n",
       "       7.94328235e+02, 1.00000000e+03, 1.25892541e+03, 1.58489319e+03,\n",
       "       1.99526231e+03, 2.51188643e+03, 3.16227766e+03, 3.98107171e+03,\n",
       "       5.01187234e+03, 6.30957344e+03, 7.94328235e+03, 1.00000000e+04,\n",
       "       1.25892541e+04, 1.58489319e+04, 1.99526231e+04, 2.51188643e+04,\n",
       "       3.16227766e+04, 3.98107171e+04, 5.01187234e+04, 6.30957344e+04,\n",
       "       7.94328235e+04, 1.00000000e+05])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 score:\n",
    "k = 10\n",
    "l2scores = np.empty(shape=0)\n",
    "\n",
    "for alpha in alphas:\n",
    "\n",
    "    model = LogisticRegression(max_iter = 1000,\n",
    "                               class_weight = 'balanced', # balances weight of zeros and ones in y\n",
    "                               penalty = 'l2',\n",
    "                               solver = 'lbfgs',\n",
    "                               C = alpha\n",
    "                              )\n",
    "    logit = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', model)\n",
    "                           ])\n",
    "\n",
    "    scores_temp = cross_val_score(logit, \n",
    "                                  X, \n",
    "                                  y, \n",
    "                                  cv = k\n",
    "                                 )\n",
    "    l2scores = np.append(l2scores, np.mean(scores_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 score\n",
    "l1scores = np.empty(shape=0)\n",
    "for alpha in alphas:\n",
    "\n",
    "    model = LogisticRegression(max_iter = 10000,\n",
    "                               class_weight = 'balanced', # balances weight of zeros and ones in y\n",
    "                               penalty = 'l1',\n",
    "                               solver = 'saga',\n",
    "                               C = alpha\n",
    "                              )\n",
    "    logit = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', model)\n",
    "                           ])\n",
    "\n",
    "    scores_temp = cross_val_score(logit, \n",
    "                                  X, \n",
    "                                  y, \n",
    "                                  cv = k\n",
    "                                 )\n",
    "    l1scores = np.append(l1scores, np.mean(scores_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([19.,  0.,  0.,  0.,  2., 27.,  0.,  0.,  0.,  2.]),\n",
       " array([0.86054208, 0.86054694, 0.86055179, 0.86055665, 0.8605615 ,\n",
       "        0.86056636, 0.86057121, 0.86057607, 0.86058092, 0.86058578,\n",
       "        0.86059064]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fig = plt.figure()\n",
    "#ax1 = fig.add_subplot(211)\n",
    "#ax1.set_title('Scores for Different Alphas')\n",
    "#ax1.set_ylabel('Alpha')\n",
    "#ax1.set_xlabel('Mean Accuracy')\n",
    "#plt.yscale(\"log\")\n",
    "#plt.scatter(l2scores, alphas, color = 'red')\n",
    "#plt.scatter(l1scores, alphas, color = 'blue')\n",
    "#plt.legend()\n",
    "plt.hist(l1scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the effect of penalty for a sample of only 1000 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = range(start = 1000, stop = len(y), step = 1000) \n",
    "banking_shuffled = shuffle(banking)# imported from sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 score:\n",
    "k = 10\n",
    "\n",
    "alphas = np.logspace(start = .1, stop = 5, num = 50)\n",
    "l2scores = np.empty(shape=0)\n",
    "\n",
    "for size in sizes:\n",
    "\n",
    "    y = banking_shuffled['y'].head(size)\n",
    "    X = banking_shuffled.drop('y', axis = 'columns').head(size)\n",
    "\n",
    "    model = LogisticRegression(max_iter = 1000,\n",
    "                               class_weight = 'balanced', # balances weight of zeros and ones in y\n",
    "                               penalty = 'l2',\n",
    "                               solver = 'lbfgs',\n",
    "                               C = alpha\n",
    "                              )\n",
    "    logit = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', model)\n",
    "                           ]\n",
    "                    )\n",
    "\n",
    "    scores_temp = cross_val_score(logit, \n",
    "                                  X, \n",
    "                                  y, \n",
    "                                  cv = k\n",
    "                                 )\n",
    "    l2scores = np.append(l2scores, np.mean(scores_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 score\n",
    "l1scores = np.empty(shape=0)\n",
    "for alpha in alphas:\n",
    "\n",
    "    model = LogisticRegression(max_iter = 10000,\n",
    "                               class_weight = 'balanced', # balances weight of zeros and ones in y\n",
    "                               penalty = 'l1',\n",
    "                               solver = 'saga',\n",
    "                               C = alpha\n",
    "                              )\n",
    "    logit = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', model)\n",
    "                           ])\n",
    "\n",
    "    scores_temp = cross_val_score(logit, \n",
    "                                  X, \n",
    "                                  y, \n",
    "                                  cv = k\n",
    "                                 )\n",
    "    l1scores = np.append(l1scores, np.mean(scores_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Score:  0.86\n",
      "L2 Score:  0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"L1 Score: \", meanl1)\n",
    "print(\"L2 Score: \", meanl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Doesn't make a difference in scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
